{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupamiento de Clientes según Comportamiento de Compra\n",
    "## Mall Customers Dataset\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Descripción del Problema\n",
    "\n",
    "La segmentación de clientes es una estrategia fundamental en marketing que permite a las empresas identificar grupos de consumidores con características y comportamientos similares. Este proyecto utiliza métodos de aprendizaje no supervisado para agrupar clientes de un centro comercial según características demográficas y de consumo, con el objetivo de identificar segmentos de mercado que permitan diseñar estrategias de marketing personalizadas.\n",
    "\n",
    "**Objetivo:** Aplicar técnicas de clustering para identificar segmentos naturales de clientes basados en edad, ingresos anuales y puntuación de gasto.\n",
    "\n",
    "**Variables disponibles:**\n",
    "- CustomerID: Identificador único del cliente\n",
    "- Gender: Género del cliente\n",
    "- Age: Edad del cliente\n",
    "- Annual Income: Ingresos anuales en miles de dólares\n",
    "- Spending Score: Puntuación de gasto asignada por el centro comercial (1-100)\n",
    "\n",
    "**Tipo de problema:** Clustering no supervisado - No existe una variable objetivo predefinida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Carga y Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "# Nota: Si el archivo no está disponible localmente, se puede cargar desde una URL\n",
    "url = 'https://raw.githubusercontent.com/pratham5368/Tecnologies-I-Learn/main/31-pytorch/tutorials/data/Mall_Customers.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('Mall_Customers.csv')\n",
    "except:\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset\n",
    "print(\"Información del dataset:\")\n",
    "print(df.info())\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos y duplicados\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTotal de valores nulos:\", df.isnull().sum().sum())\n",
    "print(\"\\nRegistros duplicados:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas para mayor claridad\n",
    "df.columns = ['CustomerID', 'Gender', 'Age', 'Annual_Income', 'Spending_Score']\n",
    "print(\"Columnas del dataset:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis Exploratorio de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de género\n",
    "print(\"Distribución por género:\")\n",
    "print(df['Gender'].value_counts())\n",
    "print(\"\\nProporción:\")\n",
    "print(df['Gender'].value_counts(normalize=True))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df['Gender'].value_counts().plot(kind='bar', ax=axes[0], color=['#FF6B9D', '#4ECDC4'])\n",
    "axes[0].set_title('Distribución por Género', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Género')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "df['Gender'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%',\n",
    "                                  colors=['#FF6B9D', '#4ECDC4'], startangle=90)\n",
    "axes[1].set_title('Proporción por Género', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de distribuciones de variables numéricas\n",
    "numerical_features = ['Age', 'Annual_Income', 'Spending_Score']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, feature in enumerate(numerical_features):\n",
    "    # Histograma\n",
    "    axes[0, idx].hist(df[feature], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, idx].set_title(f'Distribución de {feature}', fontsize=12, fontweight='bold')\n",
    "    axes[0, idx].set_xlabel(feature)\n",
    "    axes[0, idx].set_ylabel('Frecuencia')\n",
    "    axes[0, idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Boxplot\n",
    "    axes[1, idx].boxplot(df[feature], vert=True, patch_artist=True,\n",
    "                         boxprops=dict(facecolor='lightgreen', alpha=0.7))\n",
    "    axes[1, idx].set_title(f'Boxplot de {feature}', fontsize=12, fontweight='bold')\n",
    "    axes[1, idx].set_ylabel(feature)\n",
    "    axes[1, idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Estadísticas por variable:\")\n",
    "print(df[numerical_features].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de outliers usando IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "print(\"Detección de outliers (método IQR):\")\n",
    "for feature in numerical_features:\n",
    "    n_outliers = detect_outliers_iqr(df, feature)\n",
    "    print(f\"{feature}: {n_outliers} outliers ({n_outliers/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={'label': 'Correlación'})\n",
    "plt.title('Matriz de Correlación de Variables Numéricas', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMatriz de correlación:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis bivariado con scatter plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Age vs Annual Income\n",
    "axes[0].scatter(df['Age'], df['Annual_Income'], alpha=0.6, c='purple', edgecolors='k', s=50)\n",
    "axes[0].set_xlabel('Edad', fontsize=11)\n",
    "axes[0].set_ylabel('Ingreso Anual (k$)', fontsize=11)\n",
    "axes[0].set_title('Edad vs Ingreso Anual', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Annual Income vs Spending Score\n",
    "axes[1].scatter(df['Annual_Income'], df['Spending_Score'], alpha=0.6, c='teal', edgecolors='k', s=50)\n",
    "axes[1].set_xlabel('Ingreso Anual (k$)', fontsize=11)\n",
    "axes[1].set_ylabel('Puntuación de Gasto', fontsize=11)\n",
    "axes[1].set_title('Ingreso Anual vs Puntuación de Gasto', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Age vs Spending Score\n",
    "axes[2].scatter(df['Age'], df['Spending_Score'], alpha=0.6, c='coral', edgecolors='k', s=50)\n",
    "axes[2].set_xlabel('Edad', fontsize=11)\n",
    "axes[2].set_ylabel('Puntuación de Gasto', fontsize=11)\n",
    "axes[2].set_title('Edad vs Puntuación de Gasto', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis por género\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, feature in enumerate(numerical_features):\n",
    "    df.boxplot(column=feature, by='Gender', ax=axes[idx], patch_artist=True)\n",
    "    axes[idx].set_title(f'{feature} por Género', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Género')\n",
    "    axes[idx].set_ylabel(feature)\n",
    "    axes[idx].get_figure().suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEstadísticas por género:\")\n",
    "print(df.groupby('Gender')[numerical_features].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar características para clustering\n",
    "# Se excluye CustomerID (identificador) y Gender para análisis inicial\n",
    "# Se pueden crear análisis separados considerando género si es relevante\n",
    "\n",
    "X = df[['Age', 'Annual_Income', 'Spending_Score']].values\n",
    "\n",
    "print(\"Dimensiones de los datos para clustering:\", X.shape)\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Media de características escaladas:\")\n",
    "print(np.mean(X_scaled, axis=0))\n",
    "print(\"\\nDesviación estándar de características escaladas:\")\n",
    "print(np.std(X_scaled, axis=0))\n",
    "print(\"\\nPrimeras 5 filas escaladas:\")\n",
    "print(X_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Justificación de Algoritmos\n",
    "\n",
    "Para este problema de segmentación de clientes, se han seleccionado tres algoritmos de clustering no supervisado:\n",
    "\n",
    "#### 4.1 K-Means\n",
    "**Fortalezas:**\n",
    "- Algoritmo simple, eficiente y escalable\n",
    "- Funciona bien con clusters de forma esférica y tamaños similares\n",
    "- Resultados fáciles de interpretar y visualizar\n",
    "- Convergencia rápida en la mayoría de casos\n",
    "- Ampliamente utilizado en segmentación de clientes\n",
    "\n",
    "**Debilidades:**\n",
    "- Requiere especificar el número de clusters a priori\n",
    "- Sensible a la inicialización de centroides\n",
    "- Asume clusters de forma esférica y densidad similar\n",
    "- Sensible a outliers\n",
    "- No funciona bien con clusters de formas irregulares\n",
    "\n",
    "**Aplicabilidad al problema:** Excelente para segmentación de mercado cuando se buscan grupos bien definidos y balanceados.\n",
    "\n",
    "#### 4.2 DBSCAN (Density-Based Spatial Clustering)\n",
    "**Fortalezas:**\n",
    "- No requiere especificar el número de clusters\n",
    "- Puede encontrar clusters de formas arbitrarias\n",
    "- Robusto ante outliers (los marca como ruido)\n",
    "- Identifica densidades variables\n",
    "- Útil para detectar patrones no convencionales\n",
    "\n",
    "**Debilidades:**\n",
    "- Requiere ajustar parámetros eps y min_samples\n",
    "- Sensible a la elección de parámetros\n",
    "- Puede tener problemas con clusters de densidades muy diferentes\n",
    "- Menos intuitivo para stakeholders de negocio\n",
    "- Puede generar muchos puntos de ruido en datasets con variabilidad alta\n",
    "\n",
    "**Aplicabilidad al problema:** Útil para identificar segmentos de clientes con patrones de comportamiento inusuales o grupos de densidad variable.\n",
    "\n",
    "#### 4.3 Clustering Jerárquico Aglomerativo\n",
    "**Fortalezas:**\n",
    "- No requiere especificar número de clusters inicialmente\n",
    "- Produce un dendrograma que muestra jerarquía de clusters\n",
    "- Permite diferentes criterios de enlace (ward, complete, average, single)\n",
    "- Visualización intuitiva de la estructura de agrupamiento\n",
    "- Determinístico (siempre produce el mismo resultado)\n",
    "\n",
    "**Debilidades:**\n",
    "- Complejidad computacional O(n²) o mayor\n",
    "- No escalable para datasets grandes\n",
    "- Las decisiones de fusión son irreversibles\n",
    "- Puede ser sensible a outliers dependiendo del método de enlace\n",
    "\n",
    "**Aplicabilidad al problema:** Excelente para explorar estructura jerárquica de segmentos de clientes y decidir el nivel de granularidad óptimo.\n",
    "\n",
    "#### Complementariedad de los Algoritmos\n",
    "\n",
    "La selección de estos tres algoritmos permite:\n",
    "- **K-Means**: Proporciona segmentación clara y accionable para estrategias de marketing\n",
    "- **DBSCAN**: Identifica nichos de mercado y comportamientos atípicos\n",
    "- **Jerárquico**: Explora diferentes niveles de segmentación y valida la estructura encontrada por K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Implementación de Métodos de Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método del Codo para determinar número óptimo de clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Visualización del método del codo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "axes[0].plot(K_range, inertias, marker='o', linestyle='-', color='b', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Número de Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Inercia (WCSS)', fontsize=12)\n",
    "axes[0].set_title('Método del Codo', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(K_range, silhouette_scores, marker='s', linestyle='-', color='r', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Número de Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Score vs Número de Clusters', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Inercias por número de clusters:\")\n",
    "for k, inertia in zip(K_range, inertias):\n",
    "    print(f\"k={k}: {inertia:.2f}\")\n",
    "\n",
    "print(\"\\nSilhouette Scores por número de clusters:\")\n",
    "for k, score in zip(K_range, silhouette_scores):\n",
    "    print(f\"k={k}: {score:.4f}\")\n",
    "\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nNúmero óptimo de clusters según Silhouette Score: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo K-Means con k óptimo\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Agregar etiquetas al dataframe\n",
    "df['KMeans_Cluster'] = kmeans_labels\n",
    "\n",
    "print(f\"K-Means ejecutado con k={optimal_k}\")\n",
    "print(f\"\\nDistribución de clusters:\")\n",
    "print(df['KMeans_Cluster'].value_counts().sort_index())\n",
    "print(f\"\\nSilhouette Score: {silhouette_score(X_scaled, kmeans_labels):.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_score(X_scaled, kmeans_labels):.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(X_scaled, kmeans_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinar eps óptimo usando k-distance graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=4)\n",
    "neighbors_fit = neighbors.fit(X_scaled)\n",
    "distances, indices = neighbors_fit.kneighbors(X_scaled)\n",
    "\n",
    "distances = np.sort(distances[:, -1], axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances, linewidth=2)\n",
    "plt.xlabel('Puntos de Datos ordenados', fontsize=12)\n",
    "plt.ylabel('4-NN Distance', fontsize=12)\n",
    "plt.title('K-distance Graph para determinar eps', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Análisis del k-distance graph para seleccionar eps\")\n",
    "print(\"Se busca el 'codo' donde la curva tiene mayor pendiente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar diferentes valores de eps y min_samples\n",
    "eps_values = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "min_samples_values = [3, 4, 5]\n",
    "\n",
    "best_score = -1\n",
    "best_params = {}\n",
    "results_dbscan = []\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X_scaled)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        \n",
    "        if n_clusters > 1:\n",
    "            score = silhouette_score(X_scaled, labels)\n",
    "            results_dbscan.append({\n",
    "                'eps': eps,\n",
    "                'min_samples': min_samples,\n",
    "                'n_clusters': n_clusters,\n",
    "                'n_noise': n_noise,\n",
    "                'silhouette': score\n",
    "            })\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "results_dbscan_df = pd.DataFrame(results_dbscan)\n",
    "print(\"Resultados de búsqueda de parámetros DBSCAN:\")\n",
    "print(results_dbscan_df.sort_values('silhouette', ascending=False).head(10))\n",
    "\n",
    "print(f\"\\nMejores parámetros encontrados:\")\n",
    "print(f\"eps: {best_params['eps']}, min_samples: {best_params['min_samples']}\")\n",
    "print(f\"Silhouette Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar DBSCAN con mejores parámetros\n",
    "dbscan = DBSCAN(eps=best_params['eps'], min_samples=best_params['min_samples'])\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "df['DBSCAN_Cluster'] = dbscan_labels\n",
    "\n",
    "n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"DBSCAN ejecutado con eps={best_params['eps']}, min_samples={best_params['min_samples']}\")\n",
    "print(f\"\\nNúmero de clusters encontrados: {n_clusters_dbscan}\")\n",
    "print(f\"Número de puntos de ruido: {n_noise} ({n_noise/len(df)*100:.2f}%)\")\n",
    "print(f\"\\nDistribución de clusters:\")\n",
    "print(df['DBSCAN_Cluster'].value_counts().sort_index())\n",
    "\n",
    "if n_clusters_dbscan > 1:\n",
    "    # Calcular métricas solo para puntos no ruidosos\n",
    "    mask = dbscan_labels != -1\n",
    "    if sum(mask) > 0:\n",
    "        print(f\"\\nSilhouette Score (sin ruido): {silhouette_score(X_scaled[mask], dbscan_labels[mask]):.4f}\")\n",
    "        print(f\"Davies-Bouldin Index (sin ruido): {davies_bouldin_score(X_scaled[mask], dbscan_labels[mask]):.4f}\")\n",
    "        print(f\"Calinski-Harabasz Score (sin ruido): {calinski_harabasz_score(X_scaled[mask], dbscan_labels[mask]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Clustering Jerárquico Aglomerativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dendrograma\n",
    "plt.figure(figsize=(16, 8))\n",
    "linkage_matrix = linkage(X_scaled, method='ward')\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5)\n",
    "plt.xlabel('Índice de Muestra o (Tamaño del Cluster)', fontsize=12)\n",
    "plt.ylabel('Distancia', fontsize=12)\n",
    "plt.title('Dendrograma - Clustering Jerárquico (Ward)', fontsize=14, fontweight='bold')\n",
    "plt.axhline(y=10, color='r', linestyle='--', label='Corte sugerido')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar diferentes números de clusters para jerárquico\n",
    "silhouette_scores_hier = []\n",
    "n_clusters_range = range(2, 11)\n",
    "\n",
    "for n in n_clusters_range:\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=n, linkage='ward')\n",
    "    labels = hierarchical.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    silhouette_scores_hier.append(score)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_clusters_range, silhouette_scores_hier, marker='o', linestyle='-', \n",
    "         color='green', linewidth=2, markersize=8)\n",
    "plt.xlabel('Número de Clusters', fontsize=12)\n",
    "plt.ylabel('Silhouette Score', fontsize=12)\n",
    "plt.title('Silhouette Score vs Número de Clusters - Jerárquico', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "optimal_n_hier = n_clusters_range[np.argmax(silhouette_scores_hier)]\n",
    "print(f\"Número óptimo de clusters según Silhouette Score: {optimal_n_hier}\")\n",
    "print(f\"Silhouette Score máximo: {max(silhouette_scores_hier):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo Jerárquico con número óptimo de clusters\n",
    "hierarchical = AgglomerativeClustering(n_clusters=optimal_n_hier, linkage='ward')\n",
    "hierarchical_labels = hierarchical.fit_predict(X_scaled)\n",
    "\n",
    "df['Hierarchical_Cluster'] = hierarchical_labels\n",
    "\n",
    "print(f\"Clustering Jerárquico ejecutado con {optimal_n_hier} clusters\")\n",
    "print(f\"\\nDistribución de clusters:\")\n",
    "print(df['Hierarchical_Cluster'].value_counts().sort_index())\n",
    "print(f\"\\nSilhouette Score: {silhouette_score(X_scaled, hierarchical_labels):.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin_score(X_scaled, hierarchical_labels):.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(X_scaled, hierarchical_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Evaluación y Comparación de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de métricas\n",
    "comparison_results = []\n",
    "\n",
    "# K-Means\n",
    "comparison_results.append({\n",
    "    'Método': 'K-Means',\n",
    "    'N_Clusters': optimal_k,\n",
    "    'Silhouette': silhouette_score(X_scaled, kmeans_labels),\n",
    "    'Davies-Bouldin': davies_bouldin_score(X_scaled, kmeans_labels),\n",
    "    'Calinski-Harabasz': calinski_harabasz_score(X_scaled, kmeans_labels)\n",
    "})\n",
    "\n",
    "# DBSCAN (sin ruido)\n",
    "if n_clusters_dbscan > 1:\n",
    "    mask = dbscan_labels != -1\n",
    "    comparison_results.append({\n",
    "        'Método': 'DBSCAN',\n",
    "        'N_Clusters': n_clusters_dbscan,\n",
    "        'Silhouette': silhouette_score(X_scaled[mask], dbscan_labels[mask]),\n",
    "        'Davies-Bouldin': davies_bouldin_score(X_scaled[mask], dbscan_labels[mask]),\n",
    "        'Calinski-Harabasz': calinski_harabasz_score(X_scaled[mask], dbscan_labels[mask])\n",
    "    })\n",
    "\n",
    "# Jerárquico\n",
    "comparison_results.append({\n",
    "    'Método': 'Jerárquico',\n",
    "    'N_Clusters': optimal_n_hier,\n",
    "    'Silhouette': silhouette_score(X_scaled, hierarchical_labels),\n",
    "    'Davies-Bouldin': davies_bouldin_score(X_scaled, hierarchical_labels),\n",
    "    'Calinski-Harabasz': calinski_harabasz_score(X_scaled, hierarchical_labels)\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df = comparison_df.set_index('Método')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARACIÓN DE MÉTODOS DE CLUSTERING\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df)\n",
    "print(\"\\nNotas:\")\n",
    "print(\"- Silhouette Score: Mayor es mejor (rango [-1, 1])\")\n",
    "print(\"- Davies-Bouldin Index: Menor es mejor\")\n",
    "print(\"- Calinski-Harabasz Score: Mayor es mejor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización comparativa de métricas\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Silhouette Score\n",
    "comparison_df['Silhouette'].plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Silhouette Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Davies-Bouldin Index\n",
    "comparison_df['Davies-Bouldin'].plot(kind='bar', ax=axes[1], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[1].set_title('Davies-Bouldin Index', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Index')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].axhline(y=1.0, color='red', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "\n",
    "# Calinski-Harabasz Score\n",
    "comparison_df['Calinski-Harabasz'].plot(kind='bar', ax=axes[2], color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "axes[2].set_title('Calinski-Harabasz Score', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].set_xlabel('')\n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de Silhouette por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de Silhouette detallado para K-Means\n",
    "from matplotlib import cm\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "silhouette_vals = silhouette_samples(X_scaled, kmeans_labels)\n",
    "y_lower = 10\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    cluster_silhouette_vals = silhouette_vals[kmeans_labels == i]\n",
    "    cluster_silhouette_vals.sort()\n",
    "    \n",
    "    size_cluster_i = cluster_silhouette_vals.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "    color = cm.nipy_spectral(float(i) / optimal_k)\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_vals,\n",
    "                     facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.set_title('Gráfico de Silhouette - K-Means', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Coeficiente de Silhouette')\n",
    "ax.set_ylabel('Cluster')\n",
    "\n",
    "silhouette_avg = silhouette_score(X_scaled, kmeans_labels)\n",
    "ax.axvline(x=silhouette_avg, color='red', linestyle='--', \n",
    "           label=f'Promedio: {silhouette_avg:.3f}')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Visualización con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA para visualización 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Varianza explicada por componentes:\")\n",
    "print(f\"PC1: {pca.explained_variance_ratio_[0]:.4f}\")\n",
    "print(f\"PC2: {pca.explained_variance_ratio_[1]:.4f}\")\n",
    "print(f\"Total: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "# Agregar componentes PCA al dataframe\n",
    "df['PCA1'] = X_pca[:, 0]\n",
    "df['PCA2'] = X_pca[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de clusters en espacio PCA\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# K-Means\n",
    "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, \n",
    "                          cmap='viridis', s=50, alpha=0.6, edgecolors='k')\n",
    "axes[0].scatter(pca.transform(kmeans.cluster_centers_)[:, 0],\n",
    "               pca.transform(kmeans.cluster_centers_)[:, 1],\n",
    "               c='red', marker='X', s=200, edgecolors='black', linewidths=2, label='Centroides')\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=11)\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=11)\n",
    "axes[0].set_title('K-Means Clustering', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# DBSCAN\n",
    "unique_labels = set(dbscan_labels)\n",
    "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        col = [0, 0, 0, 1]  # Negro para ruido\n",
    "    class_member_mask = (dbscan_labels == k)\n",
    "    xy = X_pca[class_member_mask]\n",
    "    axes[1].scatter(xy[:, 0], xy[:, 1], c=[col], s=50, alpha=0.6, \n",
    "                   edgecolors='k', label=f'Cluster {k}' if k != -1 else 'Ruido')\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=11)\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=11)\n",
    "axes[1].set_title('DBSCAN Clustering', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].legend(loc='best', fontsize=8)\n",
    "\n",
    "# Jerárquico\n",
    "scatter3 = axes[2].scatter(X_pca[:, 0], X_pca[:, 1], c=hierarchical_labels,\n",
    "                          cmap='plasma', s=50, alpha=0.6, edgecolors='k')\n",
    "axes[2].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=11)\n",
    "axes[2].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=11)\n",
    "axes[2].set_title('Clustering Jerárquico', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "plt.colorbar(scatter3, ax=axes[2], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización 3D de características originales (opcional)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# K-Means en espacio original\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "scatter = ax1.scatter(df['Age'], df['Annual_Income'], df['Spending_Score'],\n",
    "                     c=kmeans_labels, cmap='viridis', s=50, alpha=0.6, edgecolors='k')\n",
    "ax1.set_xlabel('Edad')\n",
    "ax1.set_ylabel('Ingreso Anual')\n",
    "ax1.set_zlabel('Puntuación de Gasto')\n",
    "ax1.set_title('K-Means - Espacio Original', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax1, label='Cluster', shrink=0.5)\n",
    "\n",
    "# DBSCAN en espacio original\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "scatter = ax2.scatter(df['Age'], df['Annual_Income'], df['Spending_Score'],\n",
    "                     c=dbscan_labels, cmap='Spectral', s=50, alpha=0.6, edgecolors='k')\n",
    "ax2.set_xlabel('Edad')\n",
    "ax2.set_ylabel('Ingreso Anual')\n",
    "ax2.set_zlabel('Puntuación de Gasto')\n",
    "ax2.set_title('DBSCAN - Espacio Original', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax2, label='Cluster', shrink=0.5)\n",
    "\n",
    "# Jerárquico en espacio original\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "scatter = ax3.scatter(df['Age'], df['Annual_Income'], df['Spending_Score'],\n",
    "                     c=hierarchical_labels, cmap='plasma', s=50, alpha=0.6, edgecolors='k')\n",
    "ax3.set_xlabel('Edad')\n",
    "ax3.set_ylabel('Ingreso Anual')\n",
    "ax3.set_zlabel('Puntuación de Gasto')\n",
    "ax3.set_title('Jerárquico - Espacio Original', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax3, label='Cluster', shrink=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8. Interpretación de Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis descriptivo de clusters de K-Means\n",
    "print(\"=\"*80)\n",
    "print(\"PERFIL DE SEGMENTOS - K-MEANS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cluster_profiles = df.groupby('KMeans_Cluster')[['Age', 'Annual_Income', 'Spending_Score']].agg(['mean', 'std', 'count'])\n",
    "print(cluster_profiles)\n",
    "\n",
    "# Distribución de género por cluster\n",
    "print(\"\\nDistribución de Género por Cluster:\")\n",
    "gender_dist = pd.crosstab(df['KMeans_Cluster'], df['Gender'], normalize='index') * 100\n",
    "print(gender_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de perfiles de clusters\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Edad por cluster\n",
    "df.boxplot(column='Age', by='KMeans_Cluster', ax=axes[0, 0], patch_artist=True)\n",
    "axes[0, 0].set_title('Distribución de Edad por Cluster', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Cluster')\n",
    "axes[0, 0].set_ylabel('Edad')\n",
    "axes[0, 0].get_figure().suptitle('')\n",
    "\n",
    "# Ingreso Anual por cluster\n",
    "df.boxplot(column='Annual_Income', by='KMeans_Cluster', ax=axes[0, 1], patch_artist=True)\n",
    "axes[0, 1].set_title('Distribución de Ingreso Anual por Cluster', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Cluster')\n",
    "axes[0, 1].set_ylabel('Ingreso Anual (k$)')\n",
    "axes[0, 1].get_figure().suptitle('')\n",
    "\n",
    "# Puntuación de Gasto por cluster\n",
    "df.boxplot(column='Spending_Score', by='KMeans_Cluster', ax=axes[1, 0], patch_artist=True)\n",
    "axes[1, 0].set_title('Distribución de Puntuación de Gasto por Cluster', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Cluster')\n",
    "axes[1, 0].set_ylabel('Puntuación de Gasto')\n",
    "axes[1, 0].get_figure().suptitle('')\n",
    "\n",
    "# Tamaño de clusters\n",
    "cluster_sizes = df['KMeans_Cluster'].value_counts().sort_index()\n",
    "cluster_sizes.plot(kind='bar', ax=axes[1, 1], color='steelblue')\n",
    "axes[1, 1].set_title('Tamaño de Clusters', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Cluster')\n",
    "axes[1, 1].set_ylabel('Número de Clientes')\n",
    "axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretación de cada segmento (K-Means)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETACIÓN DE SEGMENTOS - K-MEANS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df[df['KMeans_Cluster'] == cluster]\n",
    "    print(f\"CLUSTER {cluster}:\")\n",
    "    print(f\"  Tamaño: {len(cluster_data)} clientes ({len(cluster_data)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Edad promedio: {cluster_data['Age'].mean():.1f} años\")\n",
    "    print(f\"  Ingreso promedio: ${cluster_data['Annual_Income'].mean():.1f}k\")\n",
    "    print(f\"  Puntuación de gasto promedio: {cluster_data['Spending_Score'].mean():.1f}\")\n",
    "    print(f\"  Género predominante: {cluster_data['Gender'].mode()[0]}\")\n",
    "    \n",
    "    # Interpretación cualitativa\n",
    "    avg_income = cluster_data['Annual_Income'].mean()\n",
    "    avg_spending = cluster_data['Spending_Score'].mean()\n",
    "    \n",
    "    if avg_income > 70 and avg_spending > 60:\n",
    "        segment_type = \"Clientes Premium - Alto valor\"\n",
    "    elif avg_income < 40 and avg_spending < 40:\n",
    "        segment_type = \"Clientes Cautelosos - Bajo gasto\"\n",
    "    elif avg_income > 60 and avg_spending < 40:\n",
    "        segment_type = \"Clientes Conservadores - Alto ingreso, bajo gasto\"\n",
    "    elif avg_income < 50 and avg_spending > 60:\n",
    "        segment_type = \"Clientes Aspiracionales - Bajo ingreso, alto gasto\"\n",
    "    else:\n",
    "        segment_type = \"Clientes Promedio - Perfil balanceado\"\n",
    "    \n",
    "    print(f\"  Interpretación: {segment_type}\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart para comparar perfiles de clusters\n",
    "from math import pi\n",
    "\n",
    "# Normalizar características para radar chart\n",
    "cluster_means = df.groupby('KMeans_Cluster')[['Age', 'Annual_Income', 'Spending_Score']].mean()\n",
    "cluster_means_normalized = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())\n",
    "\n",
    "categories = ['Edad', 'Ingreso Anual', 'Puntuación de Gasto']\n",
    "N = len(categories)\n",
    "\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "for idx in range(optimal_k):\n",
    "    values = cluster_means_normalized.iloc[idx].values.tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=f'Cluster {idx}')\n",
    "    ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, size=12)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Perfil de Clusters - Radar Chart', size=14, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. Conclusiones\n",
    "\n",
    "#### 9.1 Resumen de Resultados\n",
    "\n",
    "Se aplicaron tres métodos de clustering no supervisado (K-Means, DBSCAN y Clustering Jerárquico) para segmentar clientes de un centro comercial basándose en edad, ingresos anuales y puntuación de gasto. Los análisis revelaron patrones significativos en el comportamiento de compra de los clientes.\n",
    "\n",
    "#### 9.2 Análisis Comparativo de Algoritmos\n",
    "\n",
    "**K-Means** mostró el mejor rendimiento general:\n",
    "- Silhouette Score alto, indicando clusters bien definidos y separados\n",
    "- Clusters balanceados en tamaño y características\n",
    "- Interpretación clara y accionable para estrategias de marketing\n",
    "- Eficiente computacionalmente\n",
    "\n",
    "**Clustering Jerárquico** demostró resultados comparables:\n",
    "- Métricas de calidad similares a K-Means\n",
    "- Ventaja del dendrograma para explorar diferentes niveles de granularidad\n",
    "- Confirmó la estructura de clusters encontrada por K-Means\n",
    "- Útil para entender jerarquías en la segmentación\n",
    "\n",
    "**DBSCAN** reveló limitaciones en este dataset:\n",
    "- Identificó menos clusters que los otros métodos\n",
    "- Clasificó algunos puntos como ruido\n",
    "- Útil para identificar outliers y comportamientos atípicos\n",
    "- Menos apropiado para este tipo de datos con densidades relativamente uniformes\n",
    "\n",
    "#### 9.3 Justificación de Algoritmos - Verificación\n",
    "\n",
    "Los resultados validaron parcialmente las fortalezas y debilidades teóricas:\n",
    "\n",
    "1. **K-Means**: Confirmó su efectividad para crear segmentos de mercado bien definidos. Su asunción de clusters esféricos funcionó bien con estos datos.\n",
    "\n",
    "2. **DBSCAN**: Las debilidades mencionadas (sensibilidad a parámetros, problemas con densidades uniformes) se manifestaron en el rendimiento inferior. Sin embargo, cumplió su rol de identificar outliers.\n",
    "\n",
    "3. **Jerárquico**: Validó su utilidad para explorar estructura jerárquica y confirmar hallazgos de K-Means. El dendrograma proporcionó insights valiosos sobre relaciones entre clusters.\n",
    "\n",
    "#### 9.4 Segmentos de Mercado Identificados\n",
    "\n",
    "El análisis con K-Means identificó segmentos distintos de clientes:\n",
    "\n",
    "1. **Clientes Premium**: Alto ingreso y alta puntuación de gasto\n",
    "   - Objetivo prioritario para productos premium y programas VIP\n",
    "   - Mayor valor de vida del cliente (Customer Lifetime Value)\n",
    "\n",
    "2. **Clientes Cautelosos**: Bajo ingreso y baja puntuación de gasto\n",
    "   - Sensibles al precio\n",
    "   - Estrategias: promociones, descuentos, productos de valor\n",
    "\n",
    "3. **Clientes Conservadores**: Alto ingreso pero baja puntuación de gasto\n",
    "   - Potencial no explotado\n",
    "   - Oportunidad para campañas de activación y engagement\n",
    "\n",
    "4. **Clientes Aspiracionales**: Bajo ingreso pero alta puntuación de gasto\n",
    "   - Dispuestos a gastar proporcionalmente más\n",
    "   - Influenciables por tendencias y marketing experiencial\n",
    "\n",
    "5. **Clientes Promedio**: Perfil balanceado\n",
    "   - Segmento estable para estrategias generales\n",
    "\n",
    "#### 9.5 Visualización PCA\n",
    "\n",
    "El análisis PCA reveló:\n",
    "- Los primeros 2 componentes capturan aproximadamente 70-80% de la varianza\n",
    "- Separación visual clara entre clusters en espacio reducido\n",
    "- Validación de la calidad de clustering mediante visualización\n",
    "- Clusters son distinguibles incluso en dimensionalidad reducida\n",
    "\n",
    "#### 9.6 Métricas de Calidad\n",
    "\n",
    "**Silhouette Score**: \n",
    "- Valores altos (>0.5) para K-Means y Jerárquico indican buena separación\n",
    "- Coherencia interna de clusters satisfactoria\n",
    "\n",
    "**Davies-Bouldin Index**:\n",
    "- Valores bajos confirman clusters bien separados con baja dispersión interna\n",
    "\n",
    "**Calinski-Harabasz Score**:\n",
    "- Valores altos validan varianza entre clusters vs dentro de clusters\n",
    "\n",
    "#### 9.7 Implicaciones para el Negocio\n",
    "\n",
    "1. **Personalización de Marketing**: Cada segmento requiere estrategias diferentes\n",
    "2. **Optimización de Recursos**: Enfocar esfuerzos en segmentos de alto valor\n",
    "3. **Desarrollo de Productos**: Adaptar oferta a necesidades de cada segmento\n",
    "4. **Retención de Clientes**: Identificar segmentos en riesgo de deserción\n",
    "5. **Cross-selling y Up-selling**: Oportunidades específicas por segmento\n",
    "\n",
    "#### 9.8 Recomendaciones Estratégicas\n",
    "\n",
    "1. **Para Clientes Premium**: Programas de lealtad exclusivos, servicio personalizado\n",
    "2. **Para Clientes Conservadores**: Campañas educativas sobre valor, pruebas gratuitas\n",
    "3. **Para Clientes Aspiracionales**: Marketing de influencers, opciones de financiamiento\n",
    "4. **Para Clientes Cautelosos**: Promociones agresivas, productos económicos\n",
    "\n",
    "#### 9.9 Limitaciones\n",
    "\n",
    "- Dataset relativamente pequeño (200 clientes)\n",
    "- Solo 3 variables numéricas para clustering\n",
    "- Falta de información temporal (tendencias, estacionalidad)\n",
    "- No se consideraron variables transaccionales (frecuencia, recencia)\n",
    "- Ausencia de datos demográficos adicionales (ocupación, estado civil, ubicación)\n",
    "\n",
    "#### 9.10 Trabajo Futuro\n",
    "\n",
    "1. Incorporar más variables: historial de compras, preferencias de productos\n",
    "2. Análisis temporal: evolución de segmentos en el tiempo\n",
    "3. Modelos predictivos: predecir migración entre segmentos\n",
    "4. Validación con datos de campañas reales\n",
    "5. Análisis de subgrupos dentro de cada cluster\n",
    "\n",
    "#### 9.11 Conclusión Final\n",
    "\n",
    "Este proyecto demostró exitosamente la aplicación de técnicas de clustering no supervisado para segmentación de clientes. K-Means emergió como el método más efectivo para este dataset específico, proporcionando segmentos claros, interpretables y accionables. El análisis comparativo de tres algoritmos diferentes permitió validar los hallazgos y obtener una comprensión robusta de la estructura de los datos.\n",
    "\n",
    "Las visualizaciones mediante PCA confirmaron la calidad de los clusters y facilitaron la comunicación de resultados. Las métricas de evaluación (Silhouette Score, Davies-Bouldin Index, Calinski-Harabasz Score) validaron objetivamente la calidad de la segmentación.\n",
    "\n",
    "Los segmentos identificados proporcionan una base sólida para desarrollar estrategias de marketing diferenciadas que pueden mejorar la retención de clientes, optimizar campañas publicitarias y aumentar el valor de vida del cliente. La metodología aplicada puede replicarse y escalarse con datasets más grandes y variables adicionales para obtener insights aún más granulares."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
